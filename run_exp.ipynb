{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random, math\n",
    "import matlab\n",
    "import matlab.engine as me\n",
    "from dataSetup import generateData, generateWeights\n",
    "from recovAnalysis import recovery, structDiff\n",
    "from trainerUtil import tensorInit, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng = me.start_matlab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epoch = 25\n",
    "epsilon = 1e-4 \n",
    "recovery_delta = 1e-2\n",
    "batch_size = 20\n",
    "lr = 1e-3\n",
    "test_n = 1000\n",
    "\n",
    "## Baseline Values\n",
    "d = 20\n",
    "k = 5\n",
    "thresh_gt = 0.20\n",
    "n = 8000\n",
    "noise_sd = 0\n",
    "thresh_train = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vary n\n",
    "exp_n = [2000, 4000, 6000, 8000, 10000]\n",
    "w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "\n",
    "logFile = open('log_n.txt','w')\n",
    "for n in exp_n:\n",
    "    \n",
    "    train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "    train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "    print \"Tensor Initialization for n = \", n\n",
    "    tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)\n",
    "    \n",
    "    w_res_o, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, 0 , num_epoch, \n",
    "                                         batch_size, lr, epsilon) \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    recoveryVal_o = recovery(w_gt, v_gt, w_res_o, v_gt)\n",
    "    print recoveryVal, recoveryVal_o\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    recoveryStructure_o = structDiff(w_gt, w_res_o, recovery_delta)\n",
    "    print recoveryStructure, recoveryStructure_o\n",
    "    \n",
    "    logFile.write(str(n)+' '+str(recoveryVal)+' '+\n",
    "                  str(recoveryVal_o)+' '+str(recoveryStructure)+' '+str(recoveryStructure_o)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "n = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vary d\n",
    "exp_d = [10, 20, 40, 70, 100]\n",
    "\n",
    "logFile = open('log_d.txt','w')\n",
    "for d in exp_d:\n",
    "    w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "    train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "    train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "    print \"Tensor Initialization for d = \", d\n",
    "    tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)   \n",
    "\n",
    "    w_res_o, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, 0 , num_epoch, \n",
    "                                         batch_size, lr, epsilon) \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    recoveryVal_o = recovery(w_gt, v_gt, w_res_o, v_gt)\n",
    "    print recoveryVal, recoveryVal_o\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    recoveryStructure_o = structDiff(w_gt, w_res_o, recovery_delta)\n",
    "    print recoveryStructure, recoveryStructure_o\n",
    "    \n",
    "    logFile.write(str(d)+' '+str(recoveryVal)+' '+\n",
    "                  str(recoveryVal_o)+' '+str(recoveryStructure)+' '+str(recoveryStructure_o)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vary d\n",
    "exp_k = [2, 5, 10]\n",
    "\n",
    "logFile = open('log_k.txt','w')\n",
    "for k in exp_k:\n",
    "    w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "    train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "    train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "    print \"Tensor Initialization for k = \", k\n",
    "    tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)   \n",
    "\n",
    "    w_res_o, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, 0 , num_epoch, \n",
    "                                         batch_size, lr, epsilon) \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    recoveryVal_o = recovery(w_gt, v_gt, w_res_o, v_gt)\n",
    "    print recoveryVal, recoveryVal_o\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    recoveryStructure_o = structDiff(w_gt, w_res_o, recovery_delta)\n",
    "    print recoveryStructure, recoveryStructure_o\n",
    "    \n",
    "    logFile.write(str(k)+' '+str(recoveryVal)+' '+\n",
    "                  str(recoveryVal_o)+' '+str(recoveryStructure)+' '+str(recoveryStructure_o)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vary thresh_gt\n",
    "exp_thresh_gt = [0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "\n",
    "logFile = open('log_thresh_gt.txt','w')\n",
    "for thresh_gt in exp_thresh_gt:\n",
    "    w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "    train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "    train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "    print \"Tensor Initialization for thresh_gt = \", thresh_gt\n",
    "    tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)   \n",
    "\n",
    "    w_res_o, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, 0 , num_epoch, \n",
    "                                         batch_size, lr, epsilon) \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    recoveryVal_o = recovery(w_gt, v_gt, w_res_o, v_gt)\n",
    "    print recoveryVal, recoveryVal_o\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    recoveryStructure_o = structDiff(w_gt, w_res_o, recovery_delta)\n",
    "    print recoveryStructure, recoveryStructure_o\n",
    "    \n",
    "    logFile.write(str(thresh_gt)+' '+str(recoveryVal)+' '+\n",
    "                  str(recoveryVal_o)+' '+str(recoveryStructure)+' '+str(recoveryStructure_o)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "thresh_gt = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vary thresh_train\n",
    "exp_thresh_train = [0, 0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "\n",
    "w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "print \"Tensor Initialization for thresh_train\"\n",
    "tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "logFile = open('log_thresh_train.txt','w')\n",
    "for thresh_train in exp_thresh_train:\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)   \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    print recoveryVal\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    print recoveryStructure\n",
    "    \n",
    "    logFile.write(str(thresh_train)+' '+str(recoveryVal)+' '+str(recoveryStructure)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "thresh_train = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vary noise_sd\n",
    "exp_noise_sd = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "w_gt, v_gt, m =  generateWeights(d, k, thresh_gt)\n",
    "train_x, train_y, test_x, test_y = generateData(w_gt, v_gt, n, test_n, d)\n",
    "\n",
    "logFile = open('log_noise_sd.txt','w')\n",
    "for noise_sd in exp_noise_sd:\n",
    "\n",
    "    train_y_noisy = train_y + np.random.normal(0, noise_sd, n)\n",
    "\n",
    "    print \"Tensor Initialization for noise_sd = \", noise_sd\n",
    "    tensorWeights = tensorInit(train_x, train_y_noisy, w_gt, m ,k, eng)\n",
    "\n",
    "    w_res, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, thresh_train, num_epoch, \n",
    "                                         batch_size, lr, epsilon)   \n",
    "\n",
    "    w_res_o, train_loss, test_loss = train(train_x, train_y_noisy, test_x, test_y, \n",
    "                                         tensorWeights,v_gt, 0 , num_epoch, \n",
    "                                         batch_size, lr, epsilon) \n",
    "\n",
    "    recoveryVal = recovery(w_gt, v_gt, w_res, v_gt)\n",
    "    recoveryVal_o = recovery(w_gt, v_gt, w_res_o, v_gt)\n",
    "    print recoveryVal, recoveryVal_o\n",
    "\n",
    "    recoveryStructure = structDiff(w_gt, w_res, recovery_delta)\n",
    "    recoveryStructure_o = structDiff(w_gt, w_res_o, recovery_delta)\n",
    "    print recoveryStructure, recoveryStructure_o\n",
    "    \n",
    "    logFile.write(str(noise_sd)+' '+str(recoveryVal)+' '+\n",
    "                  str(recoveryVal_o)+' '+str(recoveryStructure)+' '+str(recoveryStructure_o)+'\\n')\n",
    "\n",
    "logFile.close()\n",
    "noise_sd = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-py2.7-mat]",
   "language": "python",
   "name": "conda-env-tf-py2.7-mat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
